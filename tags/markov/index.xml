<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>markov on Curious Stuff Blog by Sergio Anguita</title><link>https://curiousstuff.eu/tags/markov/</link><description>Recent content in markov on Curious Stuff Blog by Sergio Anguita</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Thu, 02 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://curiousstuff.eu/tags/markov/index.xml" rel="self" type="application/rss+xml"/><item><title>How to build a markov chain in Python</title><link>https://curiousstuff.eu/post/how-to-build-a-markov-chain-in-python/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://curiousstuff.eu/post/how-to-build-a-markov-chain-in-python/</guid><description>Introducing markov chains in Python So far, we read about how a Markov Chain works, the concept of transition matrix and how we can calculate a future state probability. However, we need to be able to create our own Markov Chains from our input data. This post will show you, how you can create your own markov chain using Python 3+
Working with Markov Chains, our first approach So, what markov chain implementation should I use to build my own chain?</description></item><item><title>Introduction to Markov chains</title><link>https://curiousstuff.eu/post/introduction-to-markov-chains/</link><pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate><guid>https://curiousstuff.eu/post/introduction-to-markov-chains/</guid><description>What is a markov chain A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC). It is named after the Russian mathematician Andrei Markov (1856-1922), who introduced it in 1906.</description></item></channel></rss>