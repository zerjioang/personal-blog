<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>markovify on Curious Stuff Blog by Sergio Anguita</title><link>https://curiousstuff.eu/tags/markovify/</link><description>Recent content in markovify on Curious Stuff Blog by Sergio Anguita</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Thu, 02 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://curiousstuff.eu/tags/markovify/index.xml" rel="self" type="application/rss+xml"/><item><title>How to build a markov chain in Python</title><link>https://curiousstuff.eu/post/how-to-build-a-markov-chain-in-python/</link><pubDate>Thu, 02 Sep 2021 00:00:00 +0000</pubDate><guid>https://curiousstuff.eu/post/how-to-build-a-markov-chain-in-python/</guid><description>Introducing markov chains in Python So far, we read about how a Markov Chain works, the concept of transition matrix and how we can calculate a future state probability. However, we need to be able to create our own Markov Chains from our input data. This post will show you, how you can create your own markov chain using Python 3+
Working with Markov Chains, our first approach So, what markov chain implementation should I use to build my own chain?</description></item></channel></rss>